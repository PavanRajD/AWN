{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "Am45nv7EHZj6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am45nv7EHZj6",
        "outputId": "70887fec-ecd2-4ad6-a1a7-858466ebe79c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "TGuVSxW3Hc2G",
      "metadata": {
        "id": "TGuVSxW3Hc2G"
      },
      "outputs": [],
      "source": [
        "!mkdir dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-iGB420ZHfwT",
      "metadata": {
        "id": "-iGB420ZHfwT"
      },
      "outputs": [],
      "source": [
        "!tar -xzf \"/content/drive/MyDrive/Wireless/diabetes.tar.gz\" --directory \"/content/dataset\" --checkpoint=.100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uV6ckrVOfdaD",
      "metadata": {
        "id": "uV6ckrVOfdaD"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install keras==2.2.4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6cb473c4",
      "metadata": {
        "id": "6cb473c4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "62be302e",
      "metadata": {
        "id": "62be302e"
      },
      "outputs": [],
      "source": [
        "class SVM:\n",
        "\n",
        "  def __init__(self, X_train, y_train, X_test, y_test, val=True, val_type='k_fold', val_distribution='balanced', k=5, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.lambda_param = lambda_param\n",
        "    self.n_iters = n_iters\n",
        "\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "\n",
        "    self.val_distribution = val_distribution\n",
        "    self.val = val\n",
        "    self.val_type=val_type\n",
        "    self.val_distribution=val_distribution\n",
        "    self.k=k\n",
        "\n",
        "    self.w = np.array([])\n",
        "    self.b = None\n",
        "\n",
        "\n",
        "  def Gradient_update(self, X_train, y_train, X_val=None, y_val=None):\n",
        "\n",
        "    n_samples, n_features = X_train.shape  \n",
        "    y_ = np.where(y_train <= 0, -1, 1)\n",
        "          \n",
        "    if self.w.size == 0 and self.b is None :\n",
        "      self.w = np.zeros(n_features)\n",
        "      self.b = 0\n",
        "\n",
        "    w_best = np.zeros(n_features)\n",
        "    b_best = 0\n",
        "\n",
        "    acc_list = [] \n",
        "    for i in range(0,self.n_iters):\n",
        "      for idx, x_i in enumerate(X_train):\n",
        "        condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
        "        if condition:\n",
        "          self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
        "        else:\n",
        "          self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n",
        "          self.b -= self.lr * y_[idx]\n",
        "\n",
        "      if i%10 == 0 and self.val:\n",
        "        approx_w = np.dot(X_val, self.w) - self.b\n",
        "        approx_w = np.sign(approx_w)\n",
        "        res_w = np.where(approx_w<0, 0, approx_w)\n",
        "\n",
        "        approx_w_best = np.dot(X_val, w_best) - b_best\n",
        "        approx_w_best = np.sign(approx_w_best)\n",
        "        res_w_best = np.where(approx_w_best<0, 0, approx_w_best)\n",
        "          \n",
        "        if (accuracy_score(y_val, res_w_best) < accuracy_score(y_val, res_w)):\n",
        "          w_best = copy.deepcopy(self.w)\n",
        "          b_best = copy.deepcopy(self.b)\n",
        "        else:  \n",
        "          self.w = copy.deepcopy(w_best)\n",
        "          self.b = copy.deepcopy(b_best)  \n",
        "          break\n",
        "\n",
        "  def Cross_validation(self, val_split):\n",
        "\n",
        "    if (self.val_distribution == 'balanced'):\n",
        "      X_train0, X_val0, y_train0, y_val0 = train_test_split(self.X_train[0], self.y_train[0], test_size=val_split)\n",
        "      X_train1, X_val1, y_train1, y_val1 = train_test_split(self.X_train[1], self.y_train[1], test_size=val_split)\n",
        "\n",
        "      X_train = np.concatenate((X_train0,X_train1),axis=0)\n",
        "      y_train = np.concatenate((y_train0,y_train1),axis=0)\n",
        "\n",
        "      X_val = np.concatenate((X_val0,X_val1),axis=0)\n",
        "      y_val = np.concatenate((y_val0,y_val1),axis=0)\n",
        "\n",
        "    elif (self.val_distribution == 'unbalanced'):\n",
        "      X_train = np.concatenate((self.X_train[0],self.X_train[1]),axis=0)\n",
        "      y_train = np.concatenate((self.y_train[0],self.y_train[1]),axis=0)\n",
        "\n",
        "      X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_split)\n",
        "\n",
        "    X_train, y_train = self.random_shuffle(X_train, y_train)\n",
        "    self.Gradient_update(X_train, y_train, X_val, y_val)\n",
        "\n",
        "  def fit(self):\n",
        "    if self.val_type == 'cross_val' and self.val:\n",
        "      self.Cross_validation(0.2)\n",
        "    \n",
        "    elif not self.val:\n",
        "      X_train = np.concatenate((self.X_train[0],self.X_train[1]),axis=0)\n",
        "      y_train = np.concatenate((self.y_train[0],self.y_train[1]),axis=0)\n",
        "      X_train, y_train = self.random_shuffle(X_train, y_train)\n",
        "      self.Gradient_update(X_train, y_train)\n",
        "\n",
        "  def random_shuffle(self, X_train, y_train):\n",
        "    self.x_tr, self.x_te, self.y_tr, self.y_te = train_test_split(X_train,y_train,test_size=0.5)\n",
        "    return np.concatenate((self.x_tr, self.x_te),axis=0), np.concatenate((self.y_tr, self.y_te),axis=0)\n",
        "\n",
        "  def predict(self):\n",
        "     approx = np.dot(self.X_test, self.w) - self.b\n",
        "     approx = np.sign(approx)\n",
        "     return np.where(approx<0, 0, approx)\n",
        "\n",
        "  def accuracy(self):\n",
        "    return accuracy_score(self.y_test, self.predict())*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "cc13a291",
      "metadata": {
        "id": "cc13a291"
      },
      "outputs": [],
      "source": [
        "class Federated_SVM:\n",
        "\n",
        "  def __init__(self, n_clients=4, val=True, val_type='k_fold', val_distribution='balanced', k=5, learning_rate=0.001, lambda_param=0.01, n_iters=100):\n",
        "    self.n_clients = n_clients\n",
        "    self.learning_rate = learning_rate\n",
        "    self.lambda_param = lambda_param\n",
        "    self.n_iters = n_iters\n",
        "    self.val = val\n",
        "    self.val_type = val_type\n",
        "    self.val_distribution = val_distribution\n",
        "    self.client_distribution = []\n",
        "    self.k = k\n",
        "    self.X_test = None\n",
        "    self.y_test = None\n",
        "    self.noise = None\n",
        "    \n",
        "  def create_clients(self, X_train, y_train, X_test, y_test):\n",
        "    self.clients=[]\n",
        "    for i in range(self.n_clients):\n",
        "      self.client_distribution.append(X_train[i][0].shape[0] + X_train[i][1].shape[0])\n",
        "      self.clients.append(SVM(X_train[i],y_train[i], X_test, y_test, self.val, self.val_type, self.val_distribution, self.k, self.learning_rate, self.lambda_param, self.n_iters))\n",
        "    self.X_test = copy.deepcopy(X_test)\n",
        "    self.y_test = copy.deepcopy(y_test)\n",
        "  \n",
        "  def find_outliers(self, weights, threshold=100, increment_size = False):\n",
        "    outliers = []\n",
        "    for i in range(self.n_clients):\n",
        "        param = weights[i]\n",
        "        if isinstance(param, np.ndarray):\n",
        "            z_score = np.abs((param - np.mean(param)) / np.std(param))\n",
        "            if np.all(z_score > threshold) or (increment_size and i+1 == self.n_clients):\n",
        "                outliers.append(i+1)\n",
        "        elif isinstance(param, float) or isinstance(param, int):\n",
        "            if np.abs(param - np.mean(weights)) > threshold * np.std(weights):\n",
        "                outliers.append(i+1)\n",
        "    return outliers\n",
        "\n",
        "  def fed_averaging(self, parameter_list):\n",
        "    w = np.zeros(parameter_list[0].shape[0])\n",
        "    b = 0\n",
        "    for i in range(0,2*self.n_clients,2):\n",
        "        w = np.add(w,parameter_list[i]*self.client_distribution[i//2]/sum(self.client_distribution))\n",
        "        b = b + parameter_list[i+1]\n",
        "    return (w, b/self.n_clients)\n",
        "\n",
        "  def fit(self, g_iters, aggregator, outlier):\n",
        "    w_best = np.zeros(self.X_test.shape[1])\n",
        "    b_best = 0\n",
        "    for i in range(0,g_iters):\n",
        "      print('global round',i+1)\n",
        "      print()\n",
        "      for j in range(0,self.n_clients):\n",
        "        print('client',j+1)\n",
        "        perform_client_operation(self.clients[j].X_train[0])\n",
        "        if i==0:\n",
        "          self.clients[j].fit()\n",
        "        else:\n",
        "          self.clients[j].w = copy.deepcopy(w_agg)\n",
        "          self.clients[j].b = copy.deepcopy(b_agg)\n",
        "          self.clients[j].fit()\n",
        "        print('accuracy', self.clients[j].accuracy())\n",
        "        print()\n",
        "      \n",
        "      increment_size = False\n",
        "      if (i == g_iters - 1):\n",
        "        increment_size = True\n",
        "        print('client', j+2)\n",
        "        self.n_clients = self.n_clients + 1\n",
        "        client_dis = copy.deepcopy(self.client_distribution[0])\n",
        "        client = copy.deepcopy(self.clients[0])\n",
        "        client.X_train = replace_with_zeros(client.X_train)\n",
        "        client.y_train = replace_with_zeros(client.y_train)\n",
        "        self.client_distribution.append(client_dis)\n",
        "        self.clients.append(client)\n",
        "        perform_client_operation(self.clients[j+1].X_train[0])\n",
        "        self.clients[j+1].w = copy.deepcopy(w_agg)\n",
        "        self.clients[j+1].b = copy.deepcopy(b_agg)\n",
        "        self.clients[j+1].fit()\n",
        "        print('accuracy', self.clients[j+1].accuracy())\n",
        "        print()\n",
        "\n",
        "      parameter_list = []\n",
        "      weights = []\n",
        "      for k in range(0,self.n_clients):\n",
        "        parameter_list.append(self.clients[k].w)\n",
        "        weights.append(self.clients[k].w)\n",
        "        parameter_list.append(self.clients[k].b)\n",
        "\n",
        "      outlier_nodes = outlier(weights, increment_size=increment_size)\n",
        "      print(\"Anomaly nodes:\", outlier_nodes)\n",
        "      w_agg, b_agg = aggregator(parameter_list)\n",
        "\n",
        "      if increment_size:\n",
        "        print(\"Accuracy before removing anomaly nodes:\", self.accuracy(w_agg,b_agg))\n",
        "        parameter_list.pop()\n",
        "        self.n_clients = self.n_clients - 1\n",
        "        w_agg, b_agg = aggregator(parameter_list)\n",
        "        print(\"Accuracy after removing anomaly nodes:\", self.accuracy(w_agg,b_agg))\n",
        "        \n",
        "        \n",
        "      if self.accuracy(w_agg,b_agg)>self.accuracy(w_best,b_best) or i==0:\n",
        "        w_best=copy.deepcopy(w_agg)\n",
        "        b_best=copy.deepcopy(b_agg)\n",
        "      print('global test acc',self.accuracy(w_best,b_best))\n",
        "      print()\n",
        "\n",
        "  def predict(self,w,b):\n",
        "     approx = np.dot(self.X_test, w) - b\n",
        "     approx = np.sign(approx)\n",
        "     return np.where(approx<0, 0, 1)\n",
        "\n",
        "  def accuracy(self,w,b):\n",
        "    return accuracy_score(self.y_test, self.predict(w,b))*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "3717eac8",
      "metadata": {
        "id": "3717eac8"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def replace_with_zeros(lst):\n",
        "    if isinstance(lst, list):\n",
        "        for i in range(len(lst)):\n",
        "            lst[i] = replace_with_zeros(lst[i])\n",
        "        return lst\n",
        "    elif isinstance(lst, np.ndarray):\n",
        "        return np.zeros_like(lst)\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "def perform_client_operation(client_data, threshold = 25):\n",
        "    clf = IsolationForest(random_state=0)\n",
        "    clf.fit(client_data)\n",
        "    predicitons = clf.predict(client_data)\n",
        "    #ml = svm.SVC(kernel='linear')\n",
        "    #ml.fit(client_data, predicitons)\n",
        "    total_anomalies = np.count_nonzero(predicitons == -1)\n",
        "    print (\"anomalies found using Isolation Forest:\", total_anomalies)\n",
        "    print (\"data left to transfer after dropping anomalies:\", len(client_data) - total_anomalies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b1af6d10",
      "metadata": {
        "id": "b1af6d10"
      },
      "outputs": [],
      "source": [
        "def get_clients(class1, class2, n_clients = 3):\n",
        "\n",
        "  clients_X = []\n",
        "  clients_y = []\n",
        "\n",
        "  clientsXtest = []\n",
        "  clientsYtest = []\n",
        "\n",
        "  clusters_1 = KMeans(n_clusters=n_clients, random_state=0).fit_predict(class1)\n",
        "  clusters_2 = KMeans(n_clusters=n_clients, random_state=0).fit_predict(class2)\n",
        "\n",
        "  for i in range(n_clients):\n",
        "\n",
        "    X_train0, X_test0, y_train0, y_test0 = train_test_split(class1[clusters_1 == i],np.zeros((class1[clusters_1 == i].shape[0],)),test_size=0.2)\n",
        "    X_train1, X_test1, y_train1, y_test1 = train_test_split(class2[clusters_2 == i],np.ones((class2[clusters_2 == i].shape[0],)),test_size=0.2)\n",
        "\n",
        "    clients_X.append([X_train0, X_train1])\n",
        "    clients_y.append([y_train0, y_train1])\n",
        "\n",
        "    clientsXtest.extend([X_test0,X_test1])\n",
        "    clientsYtest.extend([y_test0,y_test1])\n",
        "\n",
        "  X_test = np.concatenate(clientsXtest,axis=0)\n",
        "  y_test = np.concatenate(clientsYtest,axis=0)\n",
        "\n",
        "  return clients_X,clients_y,X_test,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4dd3fb61",
      "metadata": {
        "id": "4dd3fb61"
      },
      "outputs": [],
      "source": [
        "def get_total_from_clients(clients_X,clients_y):\n",
        "  x_train0 = [i[0] for i in clients_X]\n",
        "  x_train0 = np.concatenate(x_train0, axis=0)\n",
        "  x_train1 = [i[1] for i in clients_X]\n",
        "  x_train1 = np.concatenate(x_train1, axis=0)\n",
        "  y_train0 = [i[0] for i in clients_y]\n",
        "  y_train0 = np.concatenate(y_train0, axis=0)\n",
        "  y_train1 = [i[1] for i in clients_y]\n",
        "  y_train1 = np.concatenate(y_train1, axis=0)\n",
        "\n",
        "  return ([x_train0,x_train1],[y_train0,y_train1])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "86cd9c93",
      "metadata": {
        "id": "86cd9c93"
      },
      "outputs": [],
      "source": [
        "def load_and_return_data(n1, n2):\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.load_dataset('/content/dataset')\n",
        "  x_total = np.concatenate((x_train, x_test), axis=0)\n",
        "  y_total = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "  # Normalizing and reshaping the data\n",
        "  x_total = x_total/255 \n",
        "  x_total = x_total.reshape(x_total.shape[0], 784)\n",
        "\n",
        "  x_n1 = x_total[y_total == n1]\n",
        "  y_n1 = y_total[y_total == n1]\n",
        "\n",
        "  x_n2 = x_total[y_total == n2]\n",
        "  y_n2 = y_total[y_total == n2]\n",
        "\n",
        "  return [(x_n1, y_n1),(x_n2, y_n2)]\n",
        "\n",
        "data = load_and_return_data(0, 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "1898aa33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1898aa33",
        "outputId": "fab183f0-7415-4360-e261-501fa58afaf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "clients_X,clients_y,X_test,y_test = get_clients(data[0][0], data[1][0], n_clients = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "284daaa5",
      "metadata": {
        "id": "284daaa5"
      },
      "outputs": [],
      "source": [
        "xtrain_gl, ytrain_gl = get_total_from_clients(clients_X,clients_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "2ebc6b52",
      "metadata": {
        "id": "2ebc6b52"
      },
      "outputs": [],
      "source": [
        "f_svm = Federated_SVM(n_clients = 10, val=False, n_iters=150)\n",
        "f_svm.create_clients(clients_X,clients_y,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "06c79d74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06c79d74",
        "outputId": "0f1aed88-e17d-4c3c-b07b-9bfe6463c96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99.42466738583244\n"
          ]
        }
      ],
      "source": [
        "clf = SVM(xtrain_gl, ytrain_gl, X_test, y_test, val=False, n_iters=1000)\n",
        "clf.fit()\n",
        "print(clf.accuracy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "8e5a65dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e5a65dd",
        "outputId": "8212a416-2215-4d09-f932-1b79609d46dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global round 1\n",
            "\n",
            "client 1\n",
            "anomalies found using Isolation Forest: 14\n",
            "data left to transfer after dropping anomalies: 659\n",
            "accuracy 93.88709097446961\n",
            "\n",
            "client 2\n",
            "anomalies found using Isolation Forest: 10\n",
            "data left to transfer after dropping anomalies: 697\n",
            "accuracy 94.4264653002517\n",
            "\n",
            "client 3\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 539\n",
            "accuracy 71.19741100323624\n",
            "\n",
            "client 4\n",
            "anomalies found using Isolation Forest: 9\n",
            "data left to transfer after dropping anomalies: 399\n",
            "accuracy 83.06364617044228\n",
            "\n",
            "client 5\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 360\n",
            "accuracy 86.01222581805106\n",
            "\n",
            "client 6\n",
            "anomalies found using Isolation Forest: 16\n",
            "data left to transfer after dropping anomalies: 612\n",
            "accuracy 93.06005034160374\n",
            "\n",
            "client 7\n",
            "anomalies found using Isolation Forest: 13\n",
            "data left to transfer after dropping anomalies: 535\n",
            "accuracy 95.68500539374327\n",
            "\n",
            "client 8\n",
            "anomalies found using Isolation Forest: 11\n",
            "data left to transfer after dropping anomalies: 357\n",
            "accuracy 89.1405969075872\n",
            "\n",
            "client 9\n",
            "anomalies found using Isolation Forest: 17\n",
            "data left to transfer after dropping anomalies: 641\n",
            "accuracy 82.09277238403452\n",
            "\n",
            "client 10\n",
            "anomalies found using Isolation Forest: 19\n",
            "data left to transfer after dropping anomalies: 585\n",
            "accuracy 73.3908665947501\n",
            "\n",
            "Anomaly nodes: []\n",
            "global test acc 97.30312837108953\n",
            "\n",
            "global round 2\n",
            "\n",
            "client 1\n",
            "anomalies found using Isolation Forest: 14\n",
            "data left to transfer after dropping anomalies: 659\n",
            "accuracy 93.99496583962603\n",
            "\n",
            "client 2\n",
            "anomalies found using Isolation Forest: 10\n",
            "data left to transfer after dropping anomalies: 697\n",
            "accuracy 93.81517439769867\n",
            "\n",
            "client 3\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 539\n",
            "accuracy 71.34124415677815\n",
            "\n",
            "client 4\n",
            "anomalies found using Isolation Forest: 9\n",
            "data left to transfer after dropping anomalies: 399\n",
            "accuracy 86.2279755483639\n",
            "\n",
            "client 5\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 360\n",
            "accuracy 86.40776699029125\n",
            "\n",
            "client 6\n",
            "anomalies found using Isolation Forest: 16\n",
            "data left to transfer after dropping anomalies: 612\n",
            "accuracy 93.13196691837469\n",
            "\n",
            "client 7\n",
            "anomalies found using Isolation Forest: 13\n",
            "data left to transfer after dropping anomalies: 535\n",
            "accuracy 95.61308881697231\n",
            "\n",
            "client 8\n",
            "anomalies found using Isolation Forest: 11\n",
            "data left to transfer after dropping anomalies: 357\n",
            "accuracy 89.82380438691119\n",
            "\n",
            "client 9\n",
            "anomalies found using Isolation Forest: 17\n",
            "data left to transfer after dropping anomalies: 641\n",
            "accuracy 82.59618842143114\n",
            "\n",
            "client 10\n",
            "anomalies found using Isolation Forest: 19\n",
            "data left to transfer after dropping anomalies: 585\n",
            "accuracy 72.9953254225099\n",
            "\n",
            "Anomaly nodes: []\n",
            "global test acc 97.30312837108953\n",
            "\n",
            "global round 3\n",
            "\n",
            "client 1\n",
            "anomalies found using Isolation Forest: 14\n",
            "data left to transfer after dropping anomalies: 659\n",
            "accuracy 93.383674937073\n",
            "\n",
            "client 2\n",
            "anomalies found using Isolation Forest: 10\n",
            "data left to transfer after dropping anomalies: 697\n",
            "accuracy 94.4264653002517\n",
            "\n",
            "client 3\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 539\n",
            "accuracy 72.09636821287306\n",
            "\n",
            "client 4\n",
            "anomalies found using Isolation Forest: 9\n",
            "data left to transfer after dropping anomalies: 399\n",
            "accuracy 87.19884933477167\n",
            "\n",
            "client 5\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 360\n",
            "accuracy 86.98309960445883\n",
            "\n",
            "client 6\n",
            "anomalies found using Isolation Forest: 16\n",
            "data left to transfer after dropping anomalies: 612\n",
            "accuracy 92.95217547644732\n",
            "\n",
            "client 7\n",
            "anomalies found using Isolation Forest: 13\n",
            "data left to transfer after dropping anomalies: 535\n",
            "accuracy 95.50521395181589\n",
            "\n",
            "client 8\n",
            "anomalies found using Isolation Forest: 11\n",
            "data left to transfer after dropping anomalies: 357\n",
            "accuracy 89.78784609852572\n",
            "\n",
            "client 9\n",
            "anomalies found using Isolation Forest: 17\n",
            "data left to transfer after dropping anomalies: 641\n",
            "accuracy 81.69723121179432\n",
            "\n",
            "client 10\n",
            "anomalies found using Isolation Forest: 19\n",
            "data left to transfer after dropping anomalies: 585\n",
            "accuracy 72.851492268968\n",
            "\n",
            "Anomaly nodes: []\n",
            "global test acc 97.30312837108953\n",
            "\n",
            "global round 4\n",
            "\n",
            "client 1\n",
            "anomalies found using Isolation Forest: 14\n",
            "data left to transfer after dropping anomalies: 659\n",
            "accuracy 93.67134124415678\n",
            "\n",
            "client 2\n",
            "anomalies found using Isolation Forest: 10\n",
            "data left to transfer after dropping anomalies: 697\n",
            "accuracy 94.35454872348076\n",
            "\n",
            "client 3\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 539\n",
            "accuracy 71.80870190578929\n",
            "\n",
            "client 4\n",
            "anomalies found using Isolation Forest: 9\n",
            "data left to transfer after dropping anomalies: 399\n",
            "accuracy 87.27076591154261\n",
            "\n",
            "client 5\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 360\n",
            "accuracy 86.73139158576052\n",
            "\n",
            "client 6\n",
            "anomalies found using Isolation Forest: 16\n",
            "data left to transfer after dropping anomalies: 612\n",
            "accuracy 92.84430061129089\n",
            "\n",
            "client 7\n",
            "anomalies found using Isolation Forest: 13\n",
            "data left to transfer after dropping anomalies: 535\n",
            "accuracy 95.18158935634663\n",
            "\n",
            "client 8\n",
            "anomalies found using Isolation Forest: 11\n",
            "data left to transfer after dropping anomalies: 357\n",
            "accuracy 89.50017979144192\n",
            "\n",
            "client 9\n",
            "anomalies found using Isolation Forest: 17\n",
            "data left to transfer after dropping anomalies: 641\n",
            "accuracy 80.7982740021575\n",
            "\n",
            "client 10\n",
            "anomalies found using Isolation Forest: 19\n",
            "data left to transfer after dropping anomalies: 585\n",
            "accuracy 73.3908665947501\n",
            "\n",
            "Anomaly nodes: []\n",
            "global test acc 97.30312837108953\n",
            "\n",
            "global round 5\n",
            "\n",
            "client 1\n",
            "anomalies found using Isolation Forest: 14\n",
            "data left to transfer after dropping anomalies: 659\n",
            "accuracy 93.31175836030205\n",
            "\n",
            "client 2\n",
            "anomalies found using Isolation Forest: 10\n",
            "data left to transfer after dropping anomalies: 697\n",
            "accuracy 94.39050701186623\n",
            "\n",
            "client 3\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 539\n",
            "accuracy 72.67170082704062\n",
            "\n",
            "client 4\n",
            "anomalies found using Isolation Forest: 9\n",
            "data left to transfer after dropping anomalies: 399\n",
            "accuracy 89.64401294498381\n",
            "\n",
            "client 5\n",
            "anomalies found using Isolation Forest: 12\n",
            "data left to transfer after dropping anomalies: 360\n",
            "accuracy 87.09097446961525\n",
            "\n",
            "client 6\n",
            "anomalies found using Isolation Forest: 16\n",
            "data left to transfer after dropping anomalies: 612\n",
            "accuracy 93.09600862998921\n",
            "\n",
            "client 7\n",
            "anomalies found using Isolation Forest: 13\n",
            "data left to transfer after dropping anomalies: 535\n",
            "accuracy 95.97267170082704\n",
            "\n",
            "client 8\n",
            "anomalies found using Isolation Forest: 11\n",
            "data left to transfer after dropping anomalies: 357\n",
            "accuracy 89.67997123336929\n",
            "\n",
            "client 9\n",
            "anomalies found using Isolation Forest: 17\n",
            "data left to transfer after dropping anomalies: 641\n",
            "accuracy 80.58252427184466\n",
            "\n",
            "client 10\n",
            "anomalies found using Isolation Forest: 19\n",
            "data left to transfer after dropping anomalies: 585\n",
            "accuracy 72.9953254225099\n",
            "\n",
            "client 11\n",
            "anomalies found using Isolation Forest: 0\n",
            "data left to transfer after dropping anomalies: 673\n",
            "accuracy 49.83818770226537\n",
            "\n",
            "Anomaly nodes: [11]\n",
            "Accuracy before removing anomaly nodes: 68.37504494786047\n",
            "Accuracy after removing anomaly nodes: 96.76375404530745\n",
            "global test acc 97.30312837108953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "f_svm.fit(5, f_svm.fed_averaging, f_svm.find_outliers)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "18c791cc",
      "metadata": {},
      "source": [
        "## Energy Efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af302084",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Data tranfering from client to server \n",
        "import pandas as pd\n",
        "import time\n",
        "data = pd.read_csv(\"diabetes_wireless.csv\") # Load diabetes dataset (in CSV format)\n",
        "output_file = []\n",
        "start_time = time.time()\n",
        "for i in range(10):\n",
        "    output_file.append(data)\n",
        "end_time = time.time()\n",
        "result = pd.concat(output_file)\n",
        "processing_time = end_time - start_time\n",
        "data_size = len(result) / 1024 # Calculate data size of dataset (in KB)\n",
        "data_transfer_rate = 1 # Define data transfer rate of network (in Mbps)\n",
        "transfer_time = (data_size * 8) / data_transfer_rate * 1000 #Calculate time it takes to transfer data (in ms)\n",
        "total_energy_consumption = 10000 # Define total energy consumption of network during data transfer operation (in Wh)\n",
        "total_energy_consumption_kWh = total_energy_consumption / 1000 # Convert total energy consumption from Wh to kWh\n",
        "energy_efficiency = total_energy_consumption_kWh / (data_size / 1024) # Calculate energy efficiency of network (in kWh per MB of data transferred)\n",
        "print(\"Energy efficiency of network: {:.4f} kWh per MB of data transferred\".format(energy_efficiency))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6522764b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.datasets import make_classification\n",
        "Number_of_Sensors = 10\n",
        "Number_of_Rounds = 5\n",
        "# Generate synthetic data\n",
        "X = pd.read_csv(\"diabetes_wireless.csv\")\n",
        "X = X.dropna()\n",
        "\n",
        "# Instantiate Isolation Forest model\n",
        "model = IsolationForest(n_estimators=100, contamination='auto', random_state=20)\n",
        "\n",
        "# Measure energy consumption before anomaly detection\n",
        "energy_before = psutil.cpu_percent(interval=1)\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Fit the model and detect anomalies\n",
        "model.fit(X)\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Measure energy consumption after anomaly detection\n",
        "energy_after = psutil.cpu_percent(interval=1)\n",
        "\n",
        "# Calculate total energy consumption in Watt-hours (Wh)\n",
        "energy_consumption = (energy_after - energy_before) * (time.time() - start_time) / 3600\n",
        "\n",
        "# Calculate energy efficiency in kWh per data point\n",
        "energy_efficiency_isolation_forest = (energy_consumption / len(X) * 1000) * Number_of_Sensors * Number_of_Rounds\n",
        "\n",
        "# Print energy efficiency\n",
        "print(\"Energy efficiency of Isolation Forest anomaly detection: {:.6f} kWh per data point\".format(energy_efficiency_isolation_forest))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b7053d",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Data tranfering from client to server and server to client\n",
        "# Define the parameters\n",
        "data_size = 307080   # in bytes\n",
        "transmission_power = 10/1000000  # in milliwatts\n",
        "distance = 1000  # in meters\n",
        "num_sensors = 10\n",
        "transmission_time = data_size/1000*1024 * 8 / (transmission_power * distance ** 2)\n",
        "energy_consumed = num_sensors * transmission_time * transmission_power / 1000   # in Joules\n",
        "energy_consumed_kwh = energy_consumed / 3600000 # Convert Joules to kWh\n",
        "energy_efficiency = data_size/1000 * num_sensors / energy_consumed_kwh # Calculate the energy efficiency\n",
        "print(\"Energy efficiency for transmitting the data from client to the server:\", energy_efficiency, \"bytes/kWh\")\n",
        "\n",
        "data_size = 307080   # in bytes\n",
        "transmission_power = 20/1000000  # in milliwatts\n",
        "distance = 1000  # in meters\n",
        "protocol_efficiency = 0.9\n",
        "num_sensors = 10\n",
        "transmission_time = data_size/1000*1024 * 8 / (transmission_power * distance ** 2)\n",
        "energy_consumed = transmission_time * transmission_power / 1000  # in Joules\n",
        "energy_consumed_kwh = energy_consumed / 3600000 # Convert Joules to kWh\n",
        "energy_efficiency = data_size/1000 * num_sensors / energy_consumed_kwh # Calculate the energy efficiency\n",
        "print(\"Energy efficiency for transmitting the data from server to the client:\", energy_efficiency, \"bytes/kWh\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cfba032",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the parameters\n",
        "data_size = 8198416  # in bytes\n",
        "num_clients = 10\n",
        "num_rounds = 5\n",
        "transmission_power = 20  # in milliwatts\n",
        "distance = 100  # in meters\n",
        "protocol_efficiency = 0.8\n",
        "\n",
        "# Calculate the energy consumed by one client per round\n",
        "transmission_time = data_size * 8 / (transmission_power * distance ** 2)\n",
        "energy_per_client_per_round = transmission_time * transmission_power / 1000 / protocol_efficiency  # in Joules\n",
        "\n",
        "# Calculate the total energy consumed by all clients\n",
        "total_energy_consumed = energy_per_client_per_round * num_clients * num_rounds\n",
        "\n",
        "# Convert Joules to kWh\n",
        "total_energy_consumed_kwh = total_energy_consumed / 3600000\n",
        "\n",
        "# Calculate the energy efficiency\n",
        "data_transmitted = data_size * num_clients * num_rounds\n",
        "energy_efficiency = data_transmitted / total_energy_consumed_kwh\n",
        "\n",
        "# Print the result\n",
        "print(\"Energy efficiency:\", energy_efficiency, \"bytes/kWh\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
